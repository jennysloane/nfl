---
title: "classification"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Questions before/during reading:

1. maths behind logistic function? 

2. what is log-odds/logit? 
  - "logistic regression model, increasing X by one unit changes the log odds by $\beta_1$ or equivalently multiplies the odds by $e^{\beta_1}$"
  - "a one-uni increase in balance is associated withan increase in the log odds of default by 0.0055 units" (p.134)... what does that mean?

3. "The estimated intercept in Table 4.1 is typically not of interest" (p.134)...why?

4. maximum likelihood vs least squares?

```{r}
set.seed(22)
library(tidyverse)
library(mlbench)
library(tidyverse)
library(janitor)
library(caTools)
library(psych)
library(devtools)
library(MASS)
library(klaR)
library(ggord)
library(GGally)
# install_github("fawda123/ggord")
```

# simulated data 
- Question: will students pass or fail?
- DVs: hours of study, hours of sleep, cups of coffee..right now some negative values
- IV: pass or fail

## study hours and pass 
- only 1 predictor
- Bayes decision boundary (in real life can't calculate the Bayes classifier, but can here because we know the distributions and parameters)
```{r}
mu_pass = 8.5
sd_pass = 1

mu_fail = 5
sd_fail = 1

pass <- rnorm(100, mean=mu_pass, sd=sd_pass) %>%
  as_tibble() %>%
  rename(study_hours = value) %>%
  mutate(pass = 1)

fail <- rnorm(100, mean=mu_fail, sd=sd_fail) %>%
  as_tibble() %>%
  rename(study_hours = value) %>%
  mutate(pass = 0)

df <- rbind(pass, fail)

df$pass <- as.factor(df$pass)

# Bayes decision boundary:
bayes_bound <- (mu_pass+mu_fail)/2

ggplot(df, aes(study_hours, fill=pass)) +
  geom_histogram() +
  geom_vline(xintercept = bayes_bound, linetype="dashed") +
  theme_bw() +
  labs(x = "Study Hours") 


```

  - right now only dependent on study hours...I'm not sure how to make like a weighted `pass` variable to take both study and sleep into account. Maybe create a new variable?
```{r}
set.seed(22)

sigma <- rbind(c(1,0.5,0.1), c(0.5,1,-0.75), c(0.1,-0.75,1))

# create the mean vector
mu <- c(5, 8, 2) 

# generate the multivariate normal distribution
df_raw <- as.data.frame(mvrnorm(n=500, mu=mu, Sigma=sigma))

df <- df_raw %>%
  as_tibble() %>%
  rename(study_hours = V1,
         sleep_hours = V2, 
         cups_coffee = V3) 

ggpairs(df)

# create a variable "pass" dependent on study hours

df <- df %>%
  mutate(pass = ifelse(study_hours>median(study_hours),
                       sample(c(0,1),n(), replace = TRUE, p=c(0.10, 0.90)),
                       sample(c(0,1),n(), replace = TRUE, p=c(0.90, 0.10))))

df$pass <- as.factor(df$pass)
```

## study hours and pass
- histogram of study hours by pass and fail
- how to separate distributions more?
```{r}
pairs.panels(df[1:3],
             bg=c("green", "red")[df$pass],
             pch=21)

df
ggplot(df, aes(study_hours, fill=pass)) +
  geom_histogram()
```


# LDA with iris data
[Linear Discriminant Analysis in R | Example with Classification Model & Bi-Plot interpretation](https://www.youtube.com/watch?v=WUCnHx0QDSI)
- estimate relationship between a single categorical DV and a set of quantitative IVs

## model  
```{r}
set.seed(555)

mydat <- as_tibble(iris)
pairs.panels(mydat[1:4],
             bg=c("red","yellow","blue")[mydat$Species],
             pch=21)

ind <- sample(2, nrow(mydat),
              replace = TRUE, 
              prob = c(.7, .3))

training <- iris[ind==1,]
testing <- iris[ind==2,]

m1 <- lda(Species ~ ., training)
m1

m1$prior
m1$counts

```

## histograms
```{r}
pred <- predict(m1, training)

pred$class
pred$posterior
pred$x

ldahist(data = pred$x[,1], g = training$Species) # LD1
ldahist(data = pred$x[,2], g = training$Species) # LD2

ggord(m1, training$Species, ylim= c(-10,10))

```

## partition plot
- linear vs quadratic 
```{r}
partimat(Species ~., data = training, method = "lda") 
partimat(Species ~., data = training, method = "qda")
```

## Confusion Matrix - training data
```{r}
p1 <- predict(m1, training)$class

conf_mat <- table(Predicted = p1, Actual = training$Species)

acc <- sum(diag(conf_mat))/sum(conf_mat)
acc 
```

## Confusion Matrix - testing data
```{r}
p2 <- predict(m1, testing)$class

conf_mat_test <- table(Predicted = p2, Actual = testing$Species)

acc <- sum(diag(conf_mat_test))/sum(conf_mat_test)
acc
```


# Breast Cancer classification problem
```{r}

data(BreastCancer)

bc_data_raw <- BreastCancer %>%
  as_tibble() %>%
  clean_names()

str(bc_data_raw)

sum(is.na(bc_data_raw))

# going to reduce data set down to 4 variables of interest
bc_data <- bc_data_raw %>%
  na.omit() %>%
  select(cl_thickness, cell_size, cell_shape, marg_adhesion, class)

str(bc_data)

# let's reduce the number of factor levels from 10 to 3
table(bc_data$cl_thickness) 
table(bc_data$cell_size) 
table(bc_data$cell_shape) 
table(bc_data$marg_adhesion) 

bc_data_clean <- bc_data %>%
  mutate(across(cl_thickness:marg_adhesion, ~ case_when(.x %in% c(1,2,3) ~ "Low", 
                                   .x %in% c(4,5,6,7) ~ "Medium",
                                   .x %in% c(8,9,10) ~ "High"))) %>%
  na.omit()

str(bc_data_clean)

bc_data_clean$cl_thickness <- factor(bc_data_clean$cl_thickness, levels = c("Low", "Medium", "High"))
bc_data_clean$cell_size <- factor(bc_data_clean$cell_size, levels = c("Low", "Medium", "High"))
bc_data_clean$cell_shape <- factor(bc_data_clean$cell_shape, levels = c("Low", "Medium", "High"))
bc_data_clean$marg_adhesion <- factor(bc_data_clean$marg_adhesion, levels = c("Low", "Medium", "High"))
```


# Data visualisation 
```{r}
ggplot(bc_data_clean, aes(cl_thickness)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()

ggplot(bc_data_clean, aes(cell_size)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()

ggplot(bc_data_clean, aes(cell_shape)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()

ggplot(bc_data_clean, aes(marg_adhesion)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()


```

# Split into training and testing data
```{r}
bc_data_clean$split <- sample.split(bc_data_clean$class, SplitRatio = 0.7)

bc_train <- bc_data_clean %>%
  filter(split == TRUE)

bc_test <- bc_data_clean %>%
  filter(split == FALSE)

bc_model <- glm(class ~ ., family = binomial(link = "logit"), data = bc_train)
summary(bc_model)

bc_test$predicted_class <- predict(bc_model, newdata = bc_test, type = "response") # not sure what this warning is?? 

# confusion matrix
confusion_mat <- table(bc_test$class, bc_test$predicted_class > 0.5) # compares actual class to predicted class 
confusion_mat

acc <- (confusion_mat[1,1]+confusion_mat[2,2])/sum(confusion_mat)
# model is 96% accurate
```

